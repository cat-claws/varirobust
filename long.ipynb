{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6631ac90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation-epoch 0. Avg-Loss: 0.5063, Accuracy: 0.9050\n",
      "Validation-epoch 1. Avg-Loss: 0.2191, Accuracy: 0.9421\n",
      "Validation-epoch 2. Avg-Loss: 0.1205, Accuracy: 0.9672\n",
      "Validation-epoch 3. Avg-Loss: 0.0824, Accuracy: 0.9747\n",
      "Validation-epoch 4. Avg-Loss: 0.0770, Accuracy: 0.9764\n",
      "Validation-epoch 5. Avg-Loss: 0.0748, Accuracy: 0.9774\n",
      "Validation-epoch 6. Avg-Loss: 0.0672, Accuracy: 0.9795\n",
      "Validation-epoch 7. Avg-Loss: 0.0550, Accuracy: 0.9827\n",
      "Validation-epoch 8. Avg-Loss: 0.0564, Accuracy: 0.9820\n",
      "Validation-epoch 9. Avg-Loss: 0.0524, Accuracy: 0.9836\n",
      "Validation-epoch 10. Avg-Loss: 0.0494, Accuracy: 0.9841\n",
      "Validation-epoch 11. Avg-Loss: 0.0530, Accuracy: 0.9828\n",
      "Validation-epoch 12. Avg-Loss: 0.0489, Accuracy: 0.9837\n",
      "Validation-epoch 13. Avg-Loss: 0.0449, Accuracy: 0.9852\n",
      "Validation-epoch 14. Avg-Loss: 0.0471, Accuracy: 0.9846\n",
      "Validation-epoch 15. Avg-Loss: 0.0460, Accuracy: 0.9860\n",
      "Validation-epoch 16. Avg-Loss: 0.0425, Accuracy: 0.9858\n",
      "Validation-epoch 17. Avg-Loss: 0.0430, Accuracy: 0.9857\n",
      "Validation-epoch 18. Avg-Loss: 0.0423, Accuracy: 0.9852\n",
      "Validation-epoch 19. Avg-Loss: 0.0401, Accuracy: 0.9855\n",
      "Validation-epoch 20. Avg-Loss: 0.0417, Accuracy: 0.9861\n",
      "Validation-epoch 21. Avg-Loss: 0.0388, Accuracy: 0.9874\n",
      "Validation-epoch 22. Avg-Loss: 0.0398, Accuracy: 0.9868\n",
      "Validation-epoch 23. Avg-Loss: 0.0387, Accuracy: 0.9876\n",
      "Validation-epoch 24. Avg-Loss: 0.0363, Accuracy: 0.9879\n",
      "Validation-epoch 25. Avg-Loss: 0.0380, Accuracy: 0.9867\n",
      "Validation-epoch 26. Avg-Loss: 0.0354, Accuracy: 0.9887\n",
      "Validation-epoch 27. Avg-Loss: 0.0366, Accuracy: 0.9880\n",
      "Validation-epoch 28. Avg-Loss: 0.0355, Accuracy: 0.9886\n",
      "Validation-epoch 29. Avg-Loss: 0.0353, Accuracy: 0.9874\n",
      "Validation-epoch 30. Avg-Loss: 0.0333, Accuracy: 0.9886\n",
      "Validation-epoch 31. Avg-Loss: 0.0347, Accuracy: 0.9884\n",
      "Validation-epoch 32. Avg-Loss: 0.0342, Accuracy: 0.9891\n",
      "Validation-epoch 33. Avg-Loss: 0.0369, Accuracy: 0.9880\n",
      "Validation-epoch 34. Avg-Loss: 0.0340, Accuracy: 0.9886\n",
      "Validation-epoch 35. Avg-Loss: 0.0305, Accuracy: 0.9901\n",
      "Validation-epoch 36. Avg-Loss: 0.0314, Accuracy: 0.9892\n",
      "Validation-epoch 37. Avg-Loss: 0.0311, Accuracy: 0.9903\n",
      "Validation-epoch 38. Avg-Loss: 0.0314, Accuracy: 0.9898\n",
      "Validation-epoch 39. Avg-Loss: 0.0328, Accuracy: 0.9887\n",
      "Validation-epoch 40. Avg-Loss: 0.0319, Accuracy: 0.9896\n",
      "Validation-epoch 41. Avg-Loss: 0.0308, Accuracy: 0.9900\n",
      "Validation-epoch 42. Avg-Loss: 0.0329, Accuracy: 0.9893\n",
      "Validation-epoch 43. Avg-Loss: 0.0320, Accuracy: 0.9890\n",
      "Validation-epoch 44. Avg-Loss: 0.0303, Accuracy: 0.9898\n",
      "Validation-epoch 45. Avg-Loss: 0.0286, Accuracy: 0.9904\n",
      "Validation-epoch 46. Avg-Loss: 0.0304, Accuracy: 0.9897\n",
      "Validation-epoch 47. Avg-Loss: 0.0317, Accuracy: 0.9906\n",
      "Validation-epoch 48. Avg-Loss: 0.0305, Accuracy: 0.9900\n",
      "Validation-epoch 49. Avg-Loss: 0.0314, Accuracy: 0.9899\n",
      "Validation-epoch 50. Avg-Loss: 0.0323, Accuracy: 0.9900\n",
      "Validation-epoch 51. Avg-Loss: 0.0317, Accuracy: 0.9896\n",
      "Validation-epoch 52. Avg-Loss: 0.0306, Accuracy: 0.9907\n",
      "Validation-epoch 53. Avg-Loss: 0.0328, Accuracy: 0.9892\n",
      "Validation-epoch 54. Avg-Loss: 0.0309, Accuracy: 0.9908\n",
      "Validation-epoch 55. Avg-Loss: 0.0311, Accuracy: 0.9902\n",
      "Validation-epoch 56. Avg-Loss: 0.0349, Accuracy: 0.9885\n",
      "Validation-epoch 57. Avg-Loss: 0.0314, Accuracy: 0.9899\n",
      "Validation-epoch 58. Avg-Loss: 0.0279, Accuracy: 0.9901\n",
      "Validation-epoch 59. Avg-Loss: 0.0310, Accuracy: 0.9903\n",
      "Validation-epoch 60. Avg-Loss: 0.0344, Accuracy: 0.9890\n",
      "Validation-epoch 61. Avg-Loss: 0.0335, Accuracy: 0.9892\n",
      "Validation-epoch 62. Avg-Loss: 0.0313, Accuracy: 0.9895\n",
      "Validation-epoch 63. Avg-Loss: 0.0298, Accuracy: 0.9896\n",
      "Validation-epoch 64. Avg-Loss: 0.0333, Accuracy: 0.9887\n",
      "Validation-epoch 65. Avg-Loss: 0.0316, Accuracy: 0.9897\n",
      "Validation-epoch 66. Avg-Loss: 0.0319, Accuracy: 0.9896\n",
      "Validation-epoch 67. Avg-Loss: 0.0303, Accuracy: 0.9896\n",
      "Validation-epoch 68. Avg-Loss: 0.0303, Accuracy: 0.9900\n",
      "Validation-epoch 69. Avg-Loss: 0.0338, Accuracy: 0.9885\n",
      "Validation-epoch 70. Avg-Loss: 0.0298, Accuracy: 0.9905\n",
      "Validation-epoch 71. Avg-Loss: 0.0333, Accuracy: 0.9901\n",
      "Validation-epoch 72. Avg-Loss: 0.0301, Accuracy: 0.9900\n",
      "Validation-epoch 73. Avg-Loss: 0.0313, Accuracy: 0.9899\n",
      "Validation-epoch 74. Avg-Loss: 0.0292, Accuracy: 0.9908\n",
      "Validation-epoch 75. Avg-Loss: 0.0307, Accuracy: 0.9904\n",
      "Validation-epoch 76. Avg-Loss: 0.0303, Accuracy: 0.9900\n",
      "Validation-epoch 77. Avg-Loss: 0.0287, Accuracy: 0.9907\n",
      "Validation-epoch 78. Avg-Loss: 0.0289, Accuracy: 0.9907\n",
      "Validation-epoch 79. Avg-Loss: 0.0285, Accuracy: 0.9913\n",
      "Validation-epoch 80. Avg-Loss: 0.0315, Accuracy: 0.9891\n",
      "Validation-epoch 81. Avg-Loss: 0.0354, Accuracy: 0.9895\n",
      "Validation-epoch 82. Avg-Loss: 0.0315, Accuracy: 0.9907\n",
      "Validation-epoch 83. Avg-Loss: 0.0284, Accuracy: 0.9907\n",
      "Validation-epoch 84. Avg-Loss: 0.0281, Accuracy: 0.9905\n",
      "Validation-epoch 85. Avg-Loss: 0.0280, Accuracy: 0.9902\n",
      "Validation-epoch 86. Avg-Loss: 0.0296, Accuracy: 0.9908\n",
      "Validation-epoch 87. Avg-Loss: 0.0298, Accuracy: 0.9905\n",
      "Validation-epoch 88. Avg-Loss: 0.0291, Accuracy: 0.9901\n",
      "Validation-epoch 89. Avg-Loss: 0.0283, Accuracy: 0.9905\n",
      "Validation-epoch 90. Avg-Loss: 0.0289, Accuracy: 0.9910\n",
      "Validation-epoch 91. Avg-Loss: 0.0299, Accuracy: 0.9913\n",
      "Validation-epoch 92. Avg-Loss: 0.0307, Accuracy: 0.9905\n",
      "Validation-epoch 93. Avg-Loss: 0.0286, Accuracy: 0.9907\n",
      "Validation-epoch 94. Avg-Loss: 0.0299, Accuracy: 0.9904\n",
      "Validation-epoch 95. Avg-Loss: 0.0319, Accuracy: 0.9896\n",
      "Validation-epoch 96. Avg-Loss: 0.0282, Accuracy: 0.9907\n",
      "Validation-epoch 97. Avg-Loss: 0.0332, Accuracy: 0.9896\n",
      "Validation-epoch 98. Avg-Loss: 0.0299, Accuracy: 0.9901\n",
      "Validation-epoch 99. Avg-Loss: 0.0296, Accuracy: 0.9903\n",
      "Validation-epoch 100. Avg-Loss: 0.0272, Accuracy: 0.9912\n",
      "Validation-epoch 101. Avg-Loss: 0.0310, Accuracy: 0.9902\n",
      "Validation-epoch 102. Avg-Loss: 0.0294, Accuracy: 0.9905\n",
      "Validation-epoch 103. Avg-Loss: 0.0303, Accuracy: 0.9907\n",
      "Validation-epoch 104. Avg-Loss: 0.0270, Accuracy: 0.9916\n",
      "Validation-epoch 105. Avg-Loss: 0.0277, Accuracy: 0.9910\n",
      "Validation-epoch 106. Avg-Loss: 0.0279, Accuracy: 0.9907\n",
      "Validation-epoch 107. Avg-Loss: 0.0298, Accuracy: 0.9914\n",
      "Validation-epoch 108. Avg-Loss: 0.0284, Accuracy: 0.9905\n",
      "Validation-epoch 109. Avg-Loss: 0.0262, Accuracy: 0.9916\n",
      "Validation-epoch 110. Avg-Loss: 0.0279, Accuracy: 0.9911\n",
      "Validation-epoch 111. Avg-Loss: 0.0272, Accuracy: 0.9909\n",
      "Validation-epoch 112. Avg-Loss: 0.0274, Accuracy: 0.9910\n",
      "Validation-epoch 113. Avg-Loss: 0.0290, Accuracy: 0.9899\n",
      "Validation-epoch 114. Avg-Loss: 0.0292, Accuracy: 0.9906\n",
      "Validation-epoch 115. Avg-Loss: 0.0274, Accuracy: 0.9914\n",
      "Validation-epoch 116. Avg-Loss: 0.0289, Accuracy: 0.9914\n",
      "Validation-epoch 117. Avg-Loss: 0.0288, Accuracy: 0.9906\n",
      "Validation-epoch 118. Avg-Loss: 0.0289, Accuracy: 0.9905\n",
      "Validation-epoch 119. Avg-Loss: 0.0273, Accuracy: 0.9915\n",
      "Validation-epoch 120. Avg-Loss: 0.0298, Accuracy: 0.9913\n",
      "Validation-epoch 121. Avg-Loss: 0.0272, Accuracy: 0.9917\n",
      "Validation-epoch 122. Avg-Loss: 0.0280, Accuracy: 0.9907\n",
      "Validation-epoch 123. Avg-Loss: 0.0294, Accuracy: 0.9903\n",
      "Validation-epoch 124. Avg-Loss: 0.0297, Accuracy: 0.9912\n",
      "Validation-epoch 125. Avg-Loss: 0.0303, Accuracy: 0.9912\n",
      "Validation-epoch 126. Avg-Loss: 0.0284, Accuracy: 0.9905\n",
      "Validation-epoch 127. Avg-Loss: 0.0305, Accuracy: 0.9908\n",
      "Validation-epoch 128. Avg-Loss: 0.0303, Accuracy: 0.9900\n",
      "Validation-epoch 129. Avg-Loss: 0.0304, Accuracy: 0.9908\n",
      "Validation-epoch 130. Avg-Loss: 0.0310, Accuracy: 0.9900\n",
      "Validation-epoch 131. Avg-Loss: 0.0282, Accuracy: 0.9913\n",
      "Validation-epoch 132. Avg-Loss: 0.0308, Accuracy: 0.9898\n",
      "Validation-epoch 133. Avg-Loss: 0.0299, Accuracy: 0.9902\n",
      "Validation-epoch 134. Avg-Loss: 0.0291, Accuracy: 0.9903\n",
      "Validation-epoch 135. Avg-Loss: 0.0288, Accuracy: 0.9901\n",
      "Validation-epoch 136. Avg-Loss: 0.0290, Accuracy: 0.9908\n",
      "Validation-epoch 137. Avg-Loss: 0.0286, Accuracy: 0.9917\n",
      "Validation-epoch 138. Avg-Loss: 0.0288, Accuracy: 0.9917\n",
      "Validation-epoch 139. Avg-Loss: 0.0314, Accuracy: 0.9902\n",
      "Validation-epoch 140. Avg-Loss: 0.0293, Accuracy: 0.9909\n",
      "Validation-epoch 141. Avg-Loss: 0.0304, Accuracy: 0.9905\n",
      "Validation-epoch 142. Avg-Loss: 0.0293, Accuracy: 0.9904\n",
      "Validation-epoch 143. Avg-Loss: 0.0304, Accuracy: 0.9907\n",
      "Validation-epoch 144. Avg-Loss: 0.0290, Accuracy: 0.9911\n",
      "Validation-epoch 145. Avg-Loss: 0.0278, Accuracy: 0.9914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation-epoch 146. Avg-Loss: 0.0292, Accuracy: 0.9899\n",
      "Validation-epoch 147. Avg-Loss: 0.0290, Accuracy: 0.9906\n",
      "Validation-epoch 148. Avg-Loss: 0.0275, Accuracy: 0.9915\n",
      "Validation-epoch 149. Avg-Loss: 0.0281, Accuracy: 0.9910\n",
      "Validation-epoch 150. Avg-Loss: 0.0280, Accuracy: 0.9910\n",
      "Validation-epoch 151. Avg-Loss: 0.0306, Accuracy: 0.9910\n",
      "Validation-epoch 152. Avg-Loss: 0.0303, Accuracy: 0.9897\n",
      "Validation-epoch 153. Avg-Loss: 0.0286, Accuracy: 0.9916\n",
      "Validation-epoch 154. Avg-Loss: 0.0289, Accuracy: 0.9903\n",
      "Validation-epoch 155. Avg-Loss: 0.0280, Accuracy: 0.9912\n",
      "Validation-epoch 156. Avg-Loss: 0.0290, Accuracy: 0.9901\n",
      "Validation-epoch 157. Avg-Loss: 0.0286, Accuracy: 0.9912\n",
      "Validation-epoch 158. Avg-Loss: 0.0303, Accuracy: 0.9912\n",
      "Validation-epoch 159. Avg-Loss: 0.0319, Accuracy: 0.9896\n",
      "Validation-epoch 160. Avg-Loss: 0.0275, Accuracy: 0.9913\n",
      "Validation-epoch 161. Avg-Loss: 0.0290, Accuracy: 0.9907\n",
      "Validation-epoch 162. Avg-Loss: 0.0303, Accuracy: 0.9902\n",
      "Validation-epoch 163. Avg-Loss: 0.0297, Accuracy: 0.9905\n",
      "Validation-epoch 164. Avg-Loss: 0.0299, Accuracy: 0.9911\n",
      "Validation-epoch 165. Avg-Loss: 0.0281, Accuracy: 0.9914\n",
      "Validation-epoch 166. Avg-Loss: 0.0294, Accuracy: 0.9909\n",
      "Validation-epoch 167. Avg-Loss: 0.0277, Accuracy: 0.9908\n",
      "Validation-epoch 168. Avg-Loss: 0.0278, Accuracy: 0.9909\n",
      "Validation-epoch 169. Avg-Loss: 0.0277, Accuracy: 0.9914\n",
      "Validation-epoch 170. Avg-Loss: 0.0266, Accuracy: 0.9915\n",
      "Validation-epoch 171. Avg-Loss: 0.0290, Accuracy: 0.9914\n",
      "Validation-epoch 172. Avg-Loss: 0.0301, Accuracy: 0.9910\n",
      "Validation-epoch 173. Avg-Loss: 0.0283, Accuracy: 0.9913\n",
      "Validation-epoch 174. Avg-Loss: 0.0305, Accuracy: 0.9902\n",
      "Validation-epoch 175. Avg-Loss: 0.0286, Accuracy: 0.9909\n",
      "Validation-epoch 176. Avg-Loss: 0.0287, Accuracy: 0.9907\n",
      "Validation-epoch 177. Avg-Loss: 0.0301, Accuracy: 0.9906\n",
      "Validation-epoch 178. Avg-Loss: 0.0286, Accuracy: 0.9908\n",
      "Validation-epoch 179. Avg-Loss: 0.0280, Accuracy: 0.9916\n",
      "Validation-epoch 180. Avg-Loss: 0.0285, Accuracy: 0.9906\n",
      "Validation-epoch 181. Avg-Loss: 0.0271, Accuracy: 0.9915\n",
      "Validation-epoch 182. Avg-Loss: 0.0273, Accuracy: 0.9916\n",
      "Validation-epoch 183. Avg-Loss: 0.0267, Accuracy: 0.9924\n",
      "Validation-epoch 184. Avg-Loss: 0.0283, Accuracy: 0.9914\n",
      "Validation-epoch 185. Avg-Loss: 0.0282, Accuracy: 0.9904\n",
      "Validation-epoch 186. Avg-Loss: 0.0282, Accuracy: 0.9917\n",
      "Validation-epoch 187. Avg-Loss: 0.0278, Accuracy: 0.9914\n",
      "Validation-epoch 188. Avg-Loss: 0.0303, Accuracy: 0.9902\n",
      "Validation-epoch 189. Avg-Loss: 0.0305, Accuracy: 0.9903\n",
      "Validation-epoch 190. Avg-Loss: 0.0295, Accuracy: 0.9903\n",
      "Validation-epoch 191. Avg-Loss: 0.0290, Accuracy: 0.9902\n",
      "Validation-epoch 192. Avg-Loss: 0.0282, Accuracy: 0.9911\n",
      "Validation-epoch 193. Avg-Loss: 0.0291, Accuracy: 0.9916\n",
      "Validation-epoch 194. Avg-Loss: 0.0308, Accuracy: 0.9901\n",
      "Validation-epoch 195. Avg-Loss: 0.0286, Accuracy: 0.9905\n",
      "Validation-epoch 196. Avg-Loss: 0.0283, Accuracy: 0.9912\n",
      "Validation-epoch 197. Avg-Loss: 0.0280, Accuracy: 0.9911\n",
      "Validation-epoch 198. Avg-Loss: 0.0274, Accuracy: 0.9903\n",
      "Validation-epoch 199. Avg-Loss: 0.0270, Accuracy: 0.9918\n",
      "Validation-epoch 200. Avg-Loss: 0.0289, Accuracy: 0.9909\n",
      "Validation-epoch 201. Avg-Loss: 0.0309, Accuracy: 0.9908\n",
      "Validation-epoch 202. Avg-Loss: 0.0277, Accuracy: 0.9911\n",
      "Validation-epoch 203. Avg-Loss: 0.0281, Accuracy: 0.9909\n",
      "Validation-epoch 204. Avg-Loss: 0.0275, Accuracy: 0.9918\n",
      "Validation-epoch 205. Avg-Loss: 0.0264, Accuracy: 0.9910\n",
      "Validation-epoch 206. Avg-Loss: 0.0264, Accuracy: 0.9919\n",
      "Validation-epoch 207. Avg-Loss: 0.0293, Accuracy: 0.9911\n",
      "Validation-epoch 208. Avg-Loss: 0.0281, Accuracy: 0.9906\n",
      "Validation-epoch 209. Avg-Loss: 0.0258, Accuracy: 0.9918\n",
      "Validation-epoch 210. Avg-Loss: 0.0316, Accuracy: 0.9902\n",
      "Validation-epoch 211. Avg-Loss: 0.0284, Accuracy: 0.9914\n",
      "Validation-epoch 212. Avg-Loss: 0.0289, Accuracy: 0.9913\n",
      "Validation-epoch 213. Avg-Loss: 0.0299, Accuracy: 0.9909\n",
      "Validation-epoch 214. Avg-Loss: 0.0308, Accuracy: 0.9902\n",
      "Validation-epoch 215. Avg-Loss: 0.0275, Accuracy: 0.9910\n",
      "Validation-epoch 216. Avg-Loss: 0.0279, Accuracy: 0.9909\n",
      "Validation-epoch 217. Avg-Loss: 0.0284, Accuracy: 0.9915\n",
      "Validation-epoch 218. Avg-Loss: 0.0296, Accuracy: 0.9908\n",
      "Validation-epoch 219. Avg-Loss: 0.0287, Accuracy: 0.9911\n",
      "Validation-epoch 220. Avg-Loss: 0.0296, Accuracy: 0.9903\n",
      "Validation-epoch 221. Avg-Loss: 0.0285, Accuracy: 0.9911\n",
      "Validation-epoch 222. Avg-Loss: 0.0282, Accuracy: 0.9918\n",
      "Validation-epoch 223. Avg-Loss: 0.0280, Accuracy: 0.9912\n",
      "Validation-epoch 224. Avg-Loss: 0.0284, Accuracy: 0.9913\n",
      "Validation-epoch 225. Avg-Loss: 0.0291, Accuracy: 0.9912\n",
      "Validation-epoch 226. Avg-Loss: 0.0277, Accuracy: 0.9914\n",
      "Validation-epoch 227. Avg-Loss: 0.0292, Accuracy: 0.9914\n",
      "Validation-epoch 228. Avg-Loss: 0.0292, Accuracy: 0.9905\n",
      "Validation-epoch 229. Avg-Loss: 0.0308, Accuracy: 0.9917\n",
      "Validation-epoch 230. Avg-Loss: 0.0301, Accuracy: 0.9912\n",
      "Validation-epoch 231. Avg-Loss: 0.0281, Accuracy: 0.9910\n",
      "Validation-epoch 232. Avg-Loss: 0.0290, Accuracy: 0.9906\n",
      "Validation-epoch 233. Avg-Loss: 0.0296, Accuracy: 0.9904\n",
      "Validation-epoch 234. Avg-Loss: 0.0267, Accuracy: 0.9912\n",
      "Validation-epoch 235. Avg-Loss: 0.0273, Accuracy: 0.9910\n",
      "Validation-epoch 236. Avg-Loss: 0.0289, Accuracy: 0.9908\n",
      "Validation-epoch 237. Avg-Loss: 0.0278, Accuracy: 0.9909\n",
      "Validation-epoch 238. Avg-Loss: 0.0300, Accuracy: 0.9905\n",
      "Validation-epoch 239. Avg-Loss: 0.0279, Accuracy: 0.9920\n",
      "Validation-epoch 240. Avg-Loss: 0.0284, Accuracy: 0.9915\n",
      "Validation-epoch 241. Avg-Loss: 0.0304, Accuracy: 0.9910\n",
      "Validation-epoch 242. Avg-Loss: 0.0274, Accuracy: 0.9911\n",
      "Validation-epoch 243. Avg-Loss: 0.0292, Accuracy: 0.9909\n",
      "Validation-epoch 244. Avg-Loss: 0.0289, Accuracy: 0.9911\n",
      "Validation-epoch 245. Avg-Loss: 0.0289, Accuracy: 0.9910\n",
      "Validation-epoch 246. Avg-Loss: 0.0290, Accuracy: 0.9912\n",
      "Validation-epoch 247. Avg-Loss: 0.0304, Accuracy: 0.9903\n",
      "Validation-epoch 248. Avg-Loss: 0.0309, Accuracy: 0.9908\n",
      "Validation-epoch 249. Avg-Loss: 0.0284, Accuracy: 0.9913\n",
      "Validation-epoch 250. Avg-Loss: 0.0290, Accuracy: 0.9908\n",
      "Validation-epoch 251. Avg-Loss: 0.0280, Accuracy: 0.9913\n",
      "Validation-epoch 252. Avg-Loss: 0.0274, Accuracy: 0.9908\n",
      "Validation-epoch 253. Avg-Loss: 0.0281, Accuracy: 0.9909\n",
      "Validation-epoch 254. Avg-Loss: 0.0299, Accuracy: 0.9905\n",
      "Validation-epoch 255. Avg-Loss: 0.0305, Accuracy: 0.9904\n",
      "Validation-epoch 256. Avg-Loss: 0.0269, Accuracy: 0.9924\n",
      "Validation-epoch 257. Avg-Loss: 0.0278, Accuracy: 0.9913\n",
      "Validation-epoch 258. Avg-Loss: 0.0270, Accuracy: 0.9918\n",
      "Validation-epoch 259. Avg-Loss: 0.0276, Accuracy: 0.9911\n",
      "Validation-epoch 260. Avg-Loss: 0.0274, Accuracy: 0.9914\n",
      "Validation-epoch 261. Avg-Loss: 0.0273, Accuracy: 0.9917\n",
      "Validation-epoch 262. Avg-Loss: 0.0270, Accuracy: 0.9916\n",
      "Validation-epoch 263. Avg-Loss: 0.0301, Accuracy: 0.9904\n",
      "Validation-epoch 264. Avg-Loss: 0.0304, Accuracy: 0.9907\n",
      "Validation-epoch 265. Avg-Loss: 0.0289, Accuracy: 0.9908\n",
      "Validation-epoch 266. Avg-Loss: 0.0283, Accuracy: 0.9917\n",
      "Validation-epoch 267. Avg-Loss: 0.0286, Accuracy: 0.9913\n",
      "Validation-epoch 268. Avg-Loss: 0.0298, Accuracy: 0.9905\n",
      "Validation-epoch 269. Avg-Loss: 0.0279, Accuracy: 0.9913\n",
      "Validation-epoch 270. Avg-Loss: 0.0304, Accuracy: 0.9908\n",
      "Validation-epoch 271. Avg-Loss: 0.0301, Accuracy: 0.9905\n",
      "Validation-epoch 272. Avg-Loss: 0.0286, Accuracy: 0.9914\n",
      "Validation-epoch 273. Avg-Loss: 0.0278, Accuracy: 0.9910\n",
      "Validation-epoch 274. Avg-Loss: 0.0284, Accuracy: 0.9909\n",
      "Validation-epoch 275. Avg-Loss: 0.0264, Accuracy: 0.9921\n",
      "Validation-epoch 276. Avg-Loss: 0.0272, Accuracy: 0.9912\n",
      "Validation-epoch 277. Avg-Loss: 0.0268, Accuracy: 0.9919\n",
      "Validation-epoch 278. Avg-Loss: 0.0278, Accuracy: 0.9906\n",
      "Validation-epoch 279. Avg-Loss: 0.0265, Accuracy: 0.9919\n",
      "Validation-epoch 280. Avg-Loss: 0.0267, Accuracy: 0.9915\n",
      "Validation-epoch 281. Avg-Loss: 0.0268, Accuracy: 0.9918\n",
      "Validation-epoch 282. Avg-Loss: 0.0252, Accuracy: 0.9925\n",
      "Validation-epoch 283. Avg-Loss: 0.0289, Accuracy: 0.9911\n",
      "Validation-epoch 284. Avg-Loss: 0.0293, Accuracy: 0.9907\n",
      "Validation-epoch 285. Avg-Loss: 0.0279, Accuracy: 0.9917\n",
      "Validation-epoch 286. Avg-Loss: 0.0286, Accuracy: 0.9916\n",
      "Validation-epoch 287. Avg-Loss: 0.0282, Accuracy: 0.9915\n",
      "Validation-epoch 288. Avg-Loss: 0.0277, Accuracy: 0.9919\n",
      "Validation-epoch 289. Avg-Loss: 0.0275, Accuracy: 0.9914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation-epoch 290. Avg-Loss: 0.0297, Accuracy: 0.9905\n",
      "Validation-epoch 291. Avg-Loss: 0.0282, Accuracy: 0.9909\n",
      "Validation-epoch 292. Avg-Loss: 0.0292, Accuracy: 0.9909\n",
      "Validation-epoch 293. Avg-Loss: 0.0285, Accuracy: 0.9908\n",
      "Validation-epoch 294. Avg-Loss: 0.0293, Accuracy: 0.9911\n",
      "Validation-epoch 295. Avg-Loss: 0.0287, Accuracy: 0.9906\n",
      "Validation-epoch 296. Avg-Loss: 0.0287, Accuracy: 0.9912\n",
      "Validation-epoch 297. Avg-Loss: 0.0276, Accuracy: 0.9910\n",
      "Validation-epoch 298. Avg-Loss: 0.0309, Accuracy: 0.9890\n",
      "Validation-epoch 299. Avg-Loss: 0.0294, Accuracy: 0.9911\n",
      "Validation-epoch 300. Avg-Loss: 0.0299, Accuracy: 0.9910\n",
      "Validation-epoch 301. Avg-Loss: 0.0280, Accuracy: 0.9912\n",
      "Validation-epoch 302. Avg-Loss: 0.0301, Accuracy: 0.9907\n",
      "Validation-epoch 303. Avg-Loss: 0.0280, Accuracy: 0.9918\n",
      "Validation-epoch 304. Avg-Loss: 0.0278, Accuracy: 0.9921\n",
      "Validation-epoch 305. Avg-Loss: 0.0258, Accuracy: 0.9922\n",
      "Validation-epoch 306. Avg-Loss: 0.0260, Accuracy: 0.9918\n",
      "Validation-epoch 307. Avg-Loss: 0.0313, Accuracy: 0.9897\n",
      "Validation-epoch 308. Avg-Loss: 0.0281, Accuracy: 0.9912\n",
      "Validation-epoch 309. Avg-Loss: 0.0273, Accuracy: 0.9912\n",
      "Validation-epoch 310. Avg-Loss: 0.0289, Accuracy: 0.9914\n",
      "Validation-epoch 311. Avg-Loss: 0.0292, Accuracy: 0.9912\n",
      "Validation-epoch 312. Avg-Loss: 0.0266, Accuracy: 0.9920\n",
      "Validation-epoch 313. Avg-Loss: 0.0294, Accuracy: 0.9906\n",
      "Validation-epoch 314. Avg-Loss: 0.0276, Accuracy: 0.9912\n",
      "Validation-epoch 315. Avg-Loss: 0.0265, Accuracy: 0.9920\n",
      "Validation-epoch 316. Avg-Loss: 0.0288, Accuracy: 0.9907\n",
      "Validation-epoch 317. Avg-Loss: 0.0274, Accuracy: 0.9910\n",
      "Validation-epoch 318. Avg-Loss: 0.0268, Accuracy: 0.9915\n",
      "Validation-epoch 319. Avg-Loss: 0.0283, Accuracy: 0.9908\n",
      "Validation-epoch 320. Avg-Loss: 0.0279, Accuracy: 0.9916\n",
      "Validation-epoch 321. Avg-Loss: 0.0259, Accuracy: 0.9917\n",
      "Validation-epoch 322. Avg-Loss: 0.0265, Accuracy: 0.9918\n",
      "Validation-epoch 323. Avg-Loss: 0.0281, Accuracy: 0.9917\n",
      "Validation-epoch 324. Avg-Loss: 0.0262, Accuracy: 0.9921\n",
      "Validation-epoch 325. Avg-Loss: 0.0262, Accuracy: 0.9917\n",
      "Validation-epoch 326. Avg-Loss: 0.0272, Accuracy: 0.9912\n",
      "Validation-epoch 327. Avg-Loss: 0.0278, Accuracy: 0.9907\n",
      "Validation-epoch 328. Avg-Loss: 0.0294, Accuracy: 0.9911\n",
      "Validation-epoch 329. Avg-Loss: 0.0281, Accuracy: 0.9917\n",
      "Validation-epoch 330. Avg-Loss: 0.0270, Accuracy: 0.9917\n",
      "Validation-epoch 331. Avg-Loss: 0.0303, Accuracy: 0.9903\n",
      "Validation-epoch 332. Avg-Loss: 0.0287, Accuracy: 0.9909\n",
      "Validation-epoch 333. Avg-Loss: 0.0286, Accuracy: 0.9907\n",
      "Validation-epoch 334. Avg-Loss: 0.0276, Accuracy: 0.9911\n",
      "Validation-epoch 335. Avg-Loss: 0.0294, Accuracy: 0.9908\n",
      "Validation-epoch 336. Avg-Loss: 0.0271, Accuracy: 0.9919\n",
      "Validation-epoch 337. Avg-Loss: 0.0279, Accuracy: 0.9917\n",
      "Validation-epoch 338. Avg-Loss: 0.0300, Accuracy: 0.9909\n",
      "Validation-epoch 339. Avg-Loss: 0.0300, Accuracy: 0.9905\n",
      "Validation-epoch 340. Avg-Loss: 0.0286, Accuracy: 0.9909\n",
      "Validation-epoch 341. Avg-Loss: 0.0284, Accuracy: 0.9908\n",
      "Validation-epoch 342. Avg-Loss: 0.0295, Accuracy: 0.9913\n",
      "Validation-epoch 343. Avg-Loss: 0.0300, Accuracy: 0.9901\n",
      "Validation-epoch 344. Avg-Loss: 0.0282, Accuracy: 0.9908\n",
      "Validation-epoch 345. Avg-Loss: 0.0279, Accuracy: 0.9909\n",
      "Validation-epoch 346. Avg-Loss: 0.0268, Accuracy: 0.9913\n",
      "Validation-epoch 347. Avg-Loss: 0.0282, Accuracy: 0.9911\n",
      "Validation-epoch 348. Avg-Loss: 0.0269, Accuracy: 0.9915\n",
      "Validation-epoch 349. Avg-Loss: 0.0262, Accuracy: 0.9910\n",
      "Validation-epoch 350. Avg-Loss: 0.0276, Accuracy: 0.9909\n",
      "Validation-epoch 351. Avg-Loss: 0.0308, Accuracy: 0.9905\n",
      "Validation-epoch 352. Avg-Loss: 0.0283, Accuracy: 0.9910\n",
      "Validation-epoch 353. Avg-Loss: 0.0295, Accuracy: 0.9910\n",
      "Validation-epoch 354. Avg-Loss: 0.0277, Accuracy: 0.9908\n",
      "Validation-epoch 355. Avg-Loss: 0.0293, Accuracy: 0.9912\n",
      "Validation-epoch 356. Avg-Loss: 0.0298, Accuracy: 0.9913\n",
      "Validation-epoch 357. Avg-Loss: 0.0286, Accuracy: 0.9913\n",
      "Validation-epoch 358. Avg-Loss: 0.0295, Accuracy: 0.9906\n",
      "Validation-epoch 359. Avg-Loss: 0.0291, Accuracy: 0.9914\n",
      "Validation-epoch 360. Avg-Loss: 0.0266, Accuracy: 0.9913\n",
      "Validation-epoch 361. Avg-Loss: 0.0300, Accuracy: 0.9908\n",
      "Validation-epoch 362. Avg-Loss: 0.0290, Accuracy: 0.9916\n",
      "Validation-epoch 363. Avg-Loss: 0.0290, Accuracy: 0.9916\n",
      "Validation-epoch 364. Avg-Loss: 0.0309, Accuracy: 0.9906\n",
      "Validation-epoch 365. Avg-Loss: 0.0311, Accuracy: 0.9908\n",
      "Validation-epoch 366. Avg-Loss: 0.0283, Accuracy: 0.9916\n",
      "Validation-epoch 367. Avg-Loss: 0.0311, Accuracy: 0.9905\n",
      "Validation-epoch 368. Avg-Loss: 0.0274, Accuracy: 0.9912\n",
      "Validation-epoch 369. Avg-Loss: 0.0299, Accuracy: 0.9907\n",
      "Validation-epoch 370. Avg-Loss: 0.0296, Accuracy: 0.9911\n",
      "Validation-epoch 371. Avg-Loss: 0.0271, Accuracy: 0.9915\n",
      "Validation-epoch 372. Avg-Loss: 0.0276, Accuracy: 0.9913\n",
      "Validation-epoch 373. Avg-Loss: 0.0269, Accuracy: 0.9919\n",
      "Validation-epoch 374. Avg-Loss: 0.0284, Accuracy: 0.9909\n",
      "Validation-epoch 375. Avg-Loss: 0.0294, Accuracy: 0.9914\n",
      "Validation-epoch 376. Avg-Loss: 0.0277, Accuracy: 0.9911\n",
      "Validation-epoch 377. Avg-Loss: 0.0271, Accuracy: 0.9914\n",
      "Validation-epoch 378. Avg-Loss: 0.0279, Accuracy: 0.9917\n",
      "Validation-epoch 379. Avg-Loss: 0.0303, Accuracy: 0.9905\n",
      "Validation-epoch 380. Avg-Loss: 0.0307, Accuracy: 0.9908\n",
      "Validation-epoch 381. Avg-Loss: 0.0283, Accuracy: 0.9915\n",
      "Validation-epoch 382. Avg-Loss: 0.0286, Accuracy: 0.9911\n",
      "Validation-epoch 383. Avg-Loss: 0.0282, Accuracy: 0.9918\n",
      "Validation-epoch 384. Avg-Loss: 0.0274, Accuracy: 0.9913\n",
      "Validation-epoch 385. Avg-Loss: 0.0270, Accuracy: 0.9912\n",
      "Validation-epoch 386. Avg-Loss: 0.0304, Accuracy: 0.9914\n",
      "Validation-epoch 387. Avg-Loss: 0.0307, Accuracy: 0.9900\n",
      "Validation-epoch 388. Avg-Loss: 0.0278, Accuracy: 0.9909\n",
      "Validation-epoch 389. Avg-Loss: 0.0304, Accuracy: 0.9905\n",
      "Validation-epoch 390. Avg-Loss: 0.0276, Accuracy: 0.9916\n",
      "Validation-epoch 391. Avg-Loss: 0.0280, Accuracy: 0.9919\n",
      "Validation-epoch 392. Avg-Loss: 0.0272, Accuracy: 0.9912\n",
      "Validation-epoch 393. Avg-Loss: 0.0281, Accuracy: 0.9910\n",
      "Validation-epoch 394. Avg-Loss: 0.0281, Accuracy: 0.9910\n",
      "Validation-epoch 395. Avg-Loss: 0.0298, Accuracy: 0.9899\n",
      "Validation-epoch 396. Avg-Loss: 0.0278, Accuracy: 0.9912\n",
      "Validation-epoch 397. Avg-Loss: 0.0280, Accuracy: 0.9905\n",
      "Validation-epoch 398. Avg-Loss: 0.0312, Accuracy: 0.9900\n",
      "Validation-epoch 399. Avg-Loss: 0.0299, Accuracy: 0.9913\n",
      "Validation-epoch 400. Avg-Loss: 0.0280, Accuracy: 0.9914\n",
      "Validation-epoch 401. Avg-Loss: 0.0294, Accuracy: 0.9904\n",
      "Validation-epoch 402. Avg-Loss: 0.0274, Accuracy: 0.9912\n",
      "Validation-epoch 403. Avg-Loss: 0.0257, Accuracy: 0.9915\n",
      "Validation-epoch 404. Avg-Loss: 0.0280, Accuracy: 0.9909\n",
      "Validation-epoch 405. Avg-Loss: 0.0269, Accuracy: 0.9913\n",
      "Validation-epoch 406. Avg-Loss: 0.0263, Accuracy: 0.9913\n",
      "Validation-epoch 407. Avg-Loss: 0.0268, Accuracy: 0.9918\n",
      "Validation-epoch 408. Avg-Loss: 0.0261, Accuracy: 0.9917\n",
      "Validation-epoch 409. Avg-Loss: 0.0279, Accuracy: 0.9915\n",
      "Validation-epoch 410. Avg-Loss: 0.0275, Accuracy: 0.9918\n",
      "Validation-epoch 411. Avg-Loss: 0.0261, Accuracy: 0.9914\n",
      "Validation-epoch 412. Avg-Loss: 0.0275, Accuracy: 0.9919\n",
      "Validation-epoch 413. Avg-Loss: 0.0283, Accuracy: 0.9912\n",
      "Validation-epoch 414. Avg-Loss: 0.0274, Accuracy: 0.9919\n",
      "Validation-epoch 415. Avg-Loss: 0.0266, Accuracy: 0.9919\n",
      "Validation-epoch 416. Avg-Loss: 0.0272, Accuracy: 0.9924\n",
      "Validation-epoch 417. Avg-Loss: 0.0276, Accuracy: 0.9923\n",
      "Validation-epoch 418. Avg-Loss: 0.0269, Accuracy: 0.9916\n",
      "Validation-epoch 419. Avg-Loss: 0.0284, Accuracy: 0.9915\n",
      "Validation-epoch 420. Avg-Loss: 0.0269, Accuracy: 0.9916\n",
      "Validation-epoch 421. Avg-Loss: 0.0289, Accuracy: 0.9914\n",
      "Validation-epoch 422. Avg-Loss: 0.0284, Accuracy: 0.9917\n",
      "Validation-epoch 423. Avg-Loss: 0.0284, Accuracy: 0.9909\n",
      "Validation-epoch 424. Avg-Loss: 0.0272, Accuracy: 0.9921\n",
      "Validation-epoch 425. Avg-Loss: 0.0261, Accuracy: 0.9921\n",
      "Validation-epoch 426. Avg-Loss: 0.0267, Accuracy: 0.9915\n",
      "Validation-epoch 427. Avg-Loss: 0.0282, Accuracy: 0.9918\n",
      "Validation-epoch 428. Avg-Loss: 0.0283, Accuracy: 0.9920\n",
      "Validation-epoch 429. Avg-Loss: 0.0272, Accuracy: 0.9916\n",
      "Validation-epoch 430. Avg-Loss: 0.0292, Accuracy: 0.9912\n",
      "Validation-epoch 431. Avg-Loss: 0.0266, Accuracy: 0.9918\n",
      "Validation-epoch 432. Avg-Loss: 0.0270, Accuracy: 0.9917\n",
      "Validation-epoch 433. Avg-Loss: 0.0271, Accuracy: 0.9924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation-epoch 434. Avg-Loss: 0.0281, Accuracy: 0.9914\n",
      "Validation-epoch 435. Avg-Loss: 0.0285, Accuracy: 0.9912\n",
      "Validation-epoch 436. Avg-Loss: 0.0270, Accuracy: 0.9919\n",
      "Validation-epoch 437. Avg-Loss: 0.0285, Accuracy: 0.9908\n",
      "Validation-epoch 438. Avg-Loss: 0.0275, Accuracy: 0.9915\n",
      "Validation-epoch 439. Avg-Loss: 0.0284, Accuracy: 0.9909\n",
      "Validation-epoch 440. Avg-Loss: 0.0274, Accuracy: 0.9913\n",
      "Validation-epoch 441. Avg-Loss: 0.0282, Accuracy: 0.9908\n",
      "Validation-epoch 442. Avg-Loss: 0.0270, Accuracy: 0.9912\n",
      "Validation-epoch 443. Avg-Loss: 0.0288, Accuracy: 0.9909\n",
      "Validation-epoch 444. Avg-Loss: 0.0271, Accuracy: 0.9913\n",
      "Validation-epoch 445. Avg-Loss: 0.0274, Accuracy: 0.9918\n",
      "Validation-epoch 446. Avg-Loss: 0.0270, Accuracy: 0.9914\n",
      "Validation-epoch 447. Avg-Loss: 0.0267, Accuracy: 0.9916\n",
      "Validation-epoch 448. Avg-Loss: 0.0280, Accuracy: 0.9912\n",
      "Validation-epoch 449. Avg-Loss: 0.0246, Accuracy: 0.9922\n",
      "Validation-epoch 450. Avg-Loss: 0.0282, Accuracy: 0.9911\n",
      "Validation-epoch 451. Avg-Loss: 0.0258, Accuracy: 0.9923\n",
      "Validation-epoch 452. Avg-Loss: 0.0264, Accuracy: 0.9919\n",
      "Validation-epoch 453. Avg-Loss: 0.0269, Accuracy: 0.9911\n",
      "Validation-epoch 454. Avg-Loss: 0.0247, Accuracy: 0.9923\n",
      "Validation-epoch 455. Avg-Loss: 0.0264, Accuracy: 0.9915\n",
      "Validation-epoch 456. Avg-Loss: 0.0266, Accuracy: 0.9920\n",
      "Validation-epoch 457. Avg-Loss: 0.0273, Accuracy: 0.9914\n",
      "Validation-epoch 458. Avg-Loss: 0.0293, Accuracy: 0.9909\n",
      "Validation-epoch 459. Avg-Loss: 0.0269, Accuracy: 0.9917\n",
      "Validation-epoch 460. Avg-Loss: 0.0278, Accuracy: 0.9921\n",
      "Validation-epoch 461. Avg-Loss: 0.0270, Accuracy: 0.9918\n",
      "Validation-epoch 462. Avg-Loss: 0.0299, Accuracy: 0.9908\n",
      "Validation-epoch 463. Avg-Loss: 0.0284, Accuracy: 0.9911\n",
      "Validation-epoch 464. Avg-Loss: 0.0269, Accuracy: 0.9918\n",
      "Validation-epoch 465. Avg-Loss: 0.0281, Accuracy: 0.9917\n",
      "Validation-epoch 466. Avg-Loss: 0.0277, Accuracy: 0.9918\n",
      "Validation-epoch 467. Avg-Loss: 0.0290, Accuracy: 0.9913\n",
      "Validation-epoch 468. Avg-Loss: 0.0294, Accuracy: 0.9912\n",
      "Validation-epoch 469. Avg-Loss: 0.0286, Accuracy: 0.9909\n",
      "Validation-epoch 470. Avg-Loss: 0.0282, Accuracy: 0.9917\n",
      "Validation-epoch 471. Avg-Loss: 0.0288, Accuracy: 0.9913\n",
      "Validation-epoch 472. Avg-Loss: 0.0301, Accuracy: 0.9911\n",
      "Validation-epoch 473. Avg-Loss: 0.0284, Accuracy: 0.9909\n",
      "Validation-epoch 474. Avg-Loss: 0.0287, Accuracy: 0.9912\n",
      "Validation-epoch 475. Avg-Loss: 0.0298, Accuracy: 0.9908\n",
      "Validation-epoch 476. Avg-Loss: 0.0289, Accuracy: 0.9910\n",
      "Validation-epoch 477. Avg-Loss: 0.0275, Accuracy: 0.9919\n",
      "Validation-epoch 478. Avg-Loss: 0.0265, Accuracy: 0.9918\n",
      "Validation-epoch 479. Avg-Loss: 0.0267, Accuracy: 0.9917\n",
      "Validation-epoch 480. Avg-Loss: 0.0264, Accuracy: 0.9918\n",
      "Validation-epoch 481. Avg-Loss: 0.0269, Accuracy: 0.9919\n",
      "Validation-epoch 482. Avg-Loss: 0.0288, Accuracy: 0.9911\n",
      "Validation-epoch 483. Avg-Loss: 0.0270, Accuracy: 0.9917\n",
      "Validation-epoch 484. Avg-Loss: 0.0269, Accuracy: 0.9922\n",
      "Validation-epoch 485. Avg-Loss: 0.0287, Accuracy: 0.9914\n",
      "Validation-epoch 486. Avg-Loss: 0.0269, Accuracy: 0.9918\n",
      "Validation-epoch 487. Avg-Loss: 0.0293, Accuracy: 0.9915\n",
      "Validation-epoch 488. Avg-Loss: 0.0279, Accuracy: 0.9918\n",
      "Validation-epoch 489. Avg-Loss: 0.0290, Accuracy: 0.9908\n",
      "Validation-epoch 490. Avg-Loss: 0.0280, Accuracy: 0.9924\n",
      "Validation-epoch 491. Avg-Loss: 0.0295, Accuracy: 0.9917\n",
      "Validation-epoch 492. Avg-Loss: 0.0286, Accuracy: 0.9916\n",
      "Validation-epoch 493. Avg-Loss: 0.0283, Accuracy: 0.9911\n",
      "Validation-epoch 494. Avg-Loss: 0.0276, Accuracy: 0.9913\n",
      "Validation-epoch 495. Avg-Loss: 0.0299, Accuracy: 0.9914\n",
      "Validation-epoch 496. Avg-Loss: 0.0287, Accuracy: 0.9914\n",
      "Validation-epoch 497. Avg-Loss: 0.0285, Accuracy: 0.9912\n",
      "Validation-epoch 498. Avg-Loss: 0.0277, Accuracy: 0.9919\n",
      "Validation-epoch 499. Avg-Loss: 0.0268, Accuracy: 0.9918\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "from utils import DeltaEnsemble\n",
    "from mnist_models import TwoLayerNN, MLP, CNN, MLPBN, ConvNet, LeNet, LeNet5\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "\n",
    "m = CNN()\n",
    "batchSize = 1000\n",
    "loss_fn = lambda x, y: F.nll_loss(torch.log(x + 1e-9), y)\n",
    "learningRate = 0.001\n",
    "\n",
    "optimizer = torch.optim.Adam(m.parameters(), lr = learningRate)\n",
    "\n",
    "num_epochs = 500\n",
    "\n",
    "utils.train_model(m, loss_fn, batchSize, utils.trainset, utils.valset, optimizer, num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ddc5665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before. Avg-Loss: 0.0268, Accuracy: 0.9918\n",
      "After. Avg-Loss: 0.2592, Accuracy: 0.9229\n"
     ]
    }
   ],
   "source": [
    "utils.attack_model(m, loss_fn, 1000, utils.valset, 400);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc27328d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9700e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before. Avg-Loss: -0.6667, Accuracy: 0.9919\n",
      "After. Avg-Loss: -0.4998, Accuracy: 0.9378\n",
      "1 0.1 0.9919 0.9378\n",
      "Before. Avg-Loss: -0.6670, Accuracy: 0.9924\n",
      "After. Avg-Loss: -0.5040, Accuracy: 0.9381\n",
      "1 0.15 0.9924 0.9381\n",
      "Before. Avg-Loss: -0.6663, Accuracy: 0.9924\n",
      "After. Avg-Loss: -0.5059, Accuracy: 0.9369\n",
      "1 0.2 0.9924 0.9369\n",
      "Before. Avg-Loss: -0.6666, Accuracy: 0.9915\n",
      "After. Avg-Loss: -0.5056, Accuracy: 0.9361\n",
      "1 0.25 0.9915 0.9361\n",
      "Before. Avg-Loss: -0.6654, Accuracy: 0.9916\n",
      "After. Avg-Loss: -0.5006, Accuracy: 0.9343\n",
      "1 0.3 0.9916 0.9343\n",
      "Before. Avg-Loss: -0.6646, Accuracy: 0.9917\n",
      "After. Avg-Loss: -0.4908, Accuracy: 0.9304\n",
      "1 0.35 0.9917 0.9304\n",
      "Before. Avg-Loss: -0.6633, Accuracy: 0.9908\n",
      "After. Avg-Loss: -0.4698, Accuracy: 0.9257\n",
      "1 0.4 0.9908 0.9257\n",
      "Before. Avg-Loss: -0.3789, Accuracy: 0.9920\n",
      "After. Avg-Loss: -0.2272, Accuracy: 0.9427\n",
      "2 0.1 0.992 0.9427\n",
      "Before. Avg-Loss: -0.3790, Accuracy: 0.9919\n",
      "After. Avg-Loss: -0.2312, Accuracy: 0.9435\n",
      "2 0.15 0.9919 0.9435\n",
      "Before. Avg-Loss: -0.3787, Accuracy: 0.9918\n",
      "After. Avg-Loss: -0.2325, Accuracy: 0.9428\n",
      "2 0.2 0.9918 0.9428\n",
      "Before. Avg-Loss: -0.3789, Accuracy: 0.9917\n",
      "After. Avg-Loss: -0.2295, Accuracy: 0.9410\n",
      "2 0.25 0.9917 0.941\n",
      "Before. Avg-Loss: -0.3780, Accuracy: 0.9914\n",
      "After. Avg-Loss: -0.2224, Accuracy: 0.9370\n",
      "2 0.3 0.9914 0.937\n",
      "Before. Avg-Loss: -0.3757, Accuracy: 0.9910\n",
      "After. Avg-Loss: -0.2086, Accuracy: 0.9329\n",
      "2 0.35 0.991 0.9329\n",
      "Before. Avg-Loss: -0.3728, Accuracy: 0.9906\n",
      "After. Avg-Loss: -0.1776, Accuracy: 0.9245\n",
      "2 0.4 0.9906 0.9245\n",
      "Before. Avg-Loss: -0.2612, Accuracy: 0.9924\n",
      "After. Avg-Loss: -0.1166, Accuracy: 0.9453\n",
      "3 0.1 0.9924 0.9453\n",
      "Before. Avg-Loss: -0.2607, Accuracy: 0.9920\n",
      "After. Avg-Loss: -0.1193, Accuracy: 0.9439\n",
      "3 0.15 0.992 0.9439\n",
      "Before. Avg-Loss: -0.2611, Accuracy: 0.9915\n",
      "After. Avg-Loss: -0.1219, Accuracy: 0.9450\n",
      "3 0.2 0.9915 0.945\n",
      "Before. Avg-Loss: -0.2610, Accuracy: 0.9915\n",
      "After. Avg-Loss: -0.1165, Accuracy: 0.9414\n",
      "3 0.25 0.9915 0.9414\n",
      "Before. Avg-Loss: -0.2601, Accuracy: 0.9916\n",
      "After. Avg-Loss: -0.1073, Accuracy: 0.9383\n",
      "3 0.3 0.9916 0.9383\n",
      "Before. Avg-Loss: -0.2584, Accuracy: 0.9910\n",
      "After. Avg-Loss: -0.0914, Accuracy: 0.9333\n",
      "3 0.35 0.991 0.9333\n",
      "Before. Avg-Loss: -0.2542, Accuracy: 0.9900\n",
      "After. Avg-Loss: -0.0537, Accuracy: 0.9192\n",
      "3 0.4 0.99 0.9192\n",
      "Before. Avg-Loss: -0.1967, Accuracy: 0.9919\n",
      "After. Avg-Loss: -0.0549, Accuracy: 0.9470\n",
      "4 0.1 0.9919 0.947\n",
      "Before. Avg-Loss: -0.1968, Accuracy: 0.9921\n",
      "After. Avg-Loss: -0.0598, Accuracy: 0.9474\n",
      "4 0.15 0.9921 0.9474\n",
      "Before. Avg-Loss: -0.1963, Accuracy: 0.9918\n",
      "After. Avg-Loss: -0.0600, Accuracy: 0.9460\n",
      "4 0.2 0.9918 0.946\n",
      "Before. Avg-Loss: -0.1960, Accuracy: 0.9912\n",
      "After. Avg-Loss: -0.0549, Accuracy: 0.9433\n",
      "4 0.25 0.9912 0.9433\n",
      "Before. Avg-Loss: -0.1950, Accuracy: 0.9907\n",
      "After. Avg-Loss: -0.0460, Accuracy: 0.9379\n",
      "4 0.3 0.9907 0.9379\n",
      "Before. Avg-Loss: -0.1928, Accuracy: 0.9907\n",
      "After. Avg-Loss: -0.0262, Accuracy: 0.9319\n",
      "4 0.35 0.9907 0.9319\n",
      "Before. Avg-Loss: -0.1885, Accuracy: 0.9897\n",
      "After. Avg-Loss: 0.0133, Accuracy: 0.9171\n",
      "4 0.4 0.9897 0.9171\n",
      "Before. Avg-Loss: -0.1608, Accuracy: 0.9919\n",
      "After. Avg-Loss: -0.0422, Accuracy: 0.9487\n",
      "5 0.1 0.9919 0.9487\n",
      "Before. Avg-Loss: -0.1607, Accuracy: 0.9918\n",
      "After. Avg-Loss: -0.0464, Accuracy: 0.9478\n",
      "5 0.15 0.9918 0.9478\n",
      "Before. Avg-Loss: -0.1608, Accuracy: 0.9916\n",
      "After. Avg-Loss: -0.0466, Accuracy: 0.9460\n",
      "5 0.2 0.9916 0.946\n",
      "Before. Avg-Loss: -0.1604, Accuracy: 0.9914\n",
      "After. Avg-Loss: -0.0407, Accuracy: 0.9439\n",
      "5 0.25 0.9914 0.9439\n",
      "Before. Avg-Loss: -0.1597, Accuracy: 0.9912\n",
      "After. Avg-Loss: -0.0330, Accuracy: 0.9396\n",
      "5 0.3 0.9912 0.9396\n",
      "Before. Avg-Loss: -0.1576, Accuracy: 0.9908\n",
      "After. Avg-Loss: -0.0129, Accuracy: 0.9313\n",
      "5 0.35 0.9908 0.9313\n",
      "Before. Avg-Loss: -0.1544, Accuracy: 0.9897\n",
      "After. Avg-Loss: 0.0241, Accuracy: 0.9177\n",
      "5 0.4 0.9897 0.9177\n",
      "Before. Avg-Loss: -0.1320, Accuracy: 0.9922\n",
      "After. Avg-Loss: -0.0120, Accuracy: 0.9483\n",
      "6 0.1 0.9922 0.9483\n",
      "Before. Avg-Loss: -0.1318, Accuracy: 0.9918\n",
      "After. Avg-Loss: -0.0156, Accuracy: 0.9478\n",
      "6 0.15 0.9918 0.9478\n",
      "Before. Avg-Loss: -0.1316, Accuracy: 0.9918\n",
      "After. Avg-Loss: -0.0149, Accuracy: 0.9461\n",
      "6 0.2 0.9918 0.9461\n",
      "Before. Avg-Loss: -0.1311, Accuracy: 0.9910\n",
      "After. Avg-Loss: -0.0090, Accuracy: 0.9432\n",
      "6 0.25 0.991 0.9432\n",
      "Before. Avg-Loss: -0.1302, Accuracy: 0.9912\n",
      "After. Avg-Loss: 0.0015, Accuracy: 0.9392\n",
      "6 0.3 0.9912 0.9392\n",
      "Before. Avg-Loss: -0.1283, Accuracy: 0.9902\n",
      "After. Avg-Loss: 0.0201, Accuracy: 0.9299\n",
      "6 0.35 0.9902 0.9299\n",
      "Before. Avg-Loss: -0.1249, Accuracy: 0.9897\n",
      "After. Avg-Loss: 0.0618, Accuracy: 0.9164\n",
      "6 0.4 0.9897 0.9164\n",
      "Before. Avg-Loss: -0.1088, Accuracy: 0.9922\n",
      "After. Avg-Loss: 0.0197, Accuracy: 0.9494\n",
      "7 0.1 0.9922 0.9494\n",
      "Before. Avg-Loss: -0.1087, Accuracy: 0.9919\n",
      "After. Avg-Loss: 0.0158, Accuracy: 0.9491\n",
      "7 0.15 0.9919 0.9491\n",
      "Before. Avg-Loss: -0.1082, Accuracy: 0.9915\n",
      "After. Avg-Loss: 0.0171, Accuracy: 0.9468\n",
      "7 0.2 0.9915 0.9468\n",
      "Before. Avg-Loss: -0.1077, Accuracy: 0.9911\n",
      "After. Avg-Loss: 0.0217, Accuracy: 0.9449\n",
      "7 0.25 0.9911 0.9449\n",
      "Before. Avg-Loss: -0.1067, Accuracy: 0.9904\n",
      "After. Avg-Loss: 0.0343, Accuracy: 0.9393\n",
      "7 0.3 0.9904 0.9393\n",
      "Before. Avg-Loss: -0.1045, Accuracy: 0.9904\n",
      "After. Avg-Loss: 0.0536, Accuracy: 0.9307\n",
      "7 0.35 0.9904 0.9307\n",
      "Before. Avg-Loss: -0.0998, Accuracy: 0.9884\n",
      "After. Avg-Loss: 0.0966, Accuracy: 0.9168\n",
      "7 0.4 0.9884 0.9168\n",
      "Before. Avg-Loss: -0.0915, Accuracy: 0.9922\n",
      "After. Avg-Loss: 0.0435, Accuracy: 0.9496\n",
      "8 0.1 0.9922 0.9496\n",
      "Before. Avg-Loss: -0.0911, Accuracy: 0.9920\n",
      "After. Avg-Loss: 0.0392, Accuracy: 0.9496\n",
      "8 0.15 0.992 0.9496\n",
      "Before. Avg-Loss: -0.0911, Accuracy: 0.9918\n",
      "After. Avg-Loss: 0.0394, Accuracy: 0.9474\n",
      "8 0.2 0.9918 0.9474\n",
      "Before. Avg-Loss: -0.0905, Accuracy: 0.9913\n",
      "After. Avg-Loss: 0.0455, Accuracy: 0.9443\n",
      "8 0.25 0.9913 0.9443\n"
     ]
    }
   ],
   "source": [
    "original_accuracy = {}\n",
    "attacked_accuracy = {}\n",
    "\n",
    "for i in range(1, 10):\n",
    "    for eps in np.linspace(0.1, 0.4, 7):\n",
    "        eps = round(eps, 2)\n",
    "        m_ = DeltaEnsemble(m, n_neighb = i, eps = eps)\n",
    "        m_.eval()\n",
    "        original_acc, _, attacked_acc, _, _ = utils.attack_model(m_, loss_fn, int(40000 // max(1, i)), utils.valset, 400)\n",
    "        print(i, eps, original_acc, attacked_acc)\n",
    "        original_accuracy[i, eps] = original_acc\n",
    "        attacked_accuracy[i, eps] = attacked_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e2cc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "arr = np.array([[k1, k2, v] for (k1, k2), v in original_accuracy.items()])\n",
    "np.save('original_accuracy', arr)\n",
    "# fig = plt.figure(figsize=(12, 12))\n",
    "# ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "plt.scatter(arr[:, 0], arr[:, 1], c = arr[:, 2], cmap = 'hot')\n",
    "plt.colorbar()\n",
    "plt.clim(0.7,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a777ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "arr = np.array([[k1, k2, v] for (k1, k2), v in attacked_accuracy.items()])\n",
    "np.save('attacked_accuracy', arr)\n",
    "# fig = plt.figure(figsize=(12, 12))\n",
    "# ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "plt.scatter(arr[:, 0], arr[:, 1], c = arr[:, 2], cmap = 'hot')\n",
    "plt.colorbar()\n",
    "plt.clim(0.7,1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
